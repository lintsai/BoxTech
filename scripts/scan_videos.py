"""
Video Scanning Script
æƒæ Midea è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰å½±ç‰‡ä¸¦è¨˜éŒ„åˆ°è³‡æ–™åº«
"""

import sys
import argparse
from pathlib import Path
import hashlib
import cv2
from datetime import datetime
import re

# Add backend to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from backend.database.connection import SessionLocal
from backend.models.schemas import Video

def calculate_file_hash(file_path: str) -> str:
    """è¨ˆç®—æª”æ¡ˆ SHA-256 hash"""
    sha256_hash = hashlib.sha256()
    with open(file_path, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()

def extract_video_info(file_path: str) -> dict:
    """æå–å½±ç‰‡è³‡è¨Š"""
    cap = cv2.VideoCapture(file_path)
    
    info = {
        'fps': int(cap.get(cv2.CAP_PROP_FPS)),
        'total_frames': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),
        'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
        'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
    }
    
    info['duration_seconds'] = info['total_frames'] / info['fps'] if info['fps'] > 0 else 0
    info['resolution'] = f"{info['width']}x{info['height']}"
    
    cap.release()
    return info

def parse_filename(filename: str) -> dict:
    """å¾æª”åè§£ææ—¥æœŸå’Œé¡å‹"""
    # ç¯„ä¾‹: 20251102-åœ˜èª²-æ‰“é¶ 01.MOV
    pattern = r"(\d{8})-(.+?)[\.\s]"
    match = re.match(pattern, filename)
    
    metadata = {}
    if match:
        date_str = match.group(1)
        type_str = match.group(2)
        
        try:
            metadata['training_date'] = datetime.strptime(date_str, "%Y%m%d")
        except Exception:
            pass
        
        metadata['training_type'] = type_str
    
    return metadata

ALLOWED_VIDEO_SUFFIXES = {'.mp4', '.mov', '.avi'}  # Exclude images like .heic by default


def scan_videos(directory: str = "./Midea", mode: str = "incremental"):
    """æƒæå½±ç‰‡è³‡æ–™å¤¾
    mode: 'incremental'ï¼ˆé è¨­ï¼‰æˆ– 'full'ã€‚full æœƒé‡æ–°è™•ç†å·²å­˜åœ¨æ–¼ DB çš„æª”æ¡ˆä¸¦æ›´æ–°æ¬„ä½ã€‚
    """
    mode = (mode or "incremental").lower()
    if mode not in {"incremental", "full"}:
        print(f"âš ï¸  Unknown mode '{mode}', fallback to 'incremental'")
        mode = "incremental"

    db = SessionLocal()
    
    # Use case-insensitive suffix filtering to avoid duplicates on Windows
    allowed_suffixes = ALLOWED_VIDEO_SUFFIXES
    base_path = Path(directory)

    # Gather files once and filter by lower-cased suffix, then deduplicate paths
    video_files = [p for p in base_path.rglob("*") if p.is_file() and p.suffix.lower() in allowed_suffixes]
    # Ensure no duplicate paths (can happen on case-insensitive filesystems when globbing with mixed-case patterns)
    seen = set()
    deduped_files = []
    for p in video_files:
        key = str(p.resolve()).lower()
        if key in seen:
            continue
        seen.add(key)
        deduped_files.append(p)
    video_files = deduped_files
    
    print(f"ğŸ“¹ Found {len(video_files)} video files")
    
    new_count = 0
    updated_count = 0
    duplicate_in_run_count = 0
    already_in_db_count = 0
    error_count = 0
    seen_hashes = set()
    
    for video_path in video_files:
        try:
            # è¨ˆç®— hash
            file_hash = calculate_file_hash(str(video_path))
            
            # å…ˆæª¢æŸ¥æ˜¯å¦åœ¨æœ¬æ¬¡åŸ·è¡Œå…§é‡è¤‡
            if file_hash in seen_hashes:
                print(f"â­ï¸  Skip (duplicate in this run): {video_path.name}")
                duplicate_in_run_count += 1
                continue

            # æª¢æŸ¥è³‡æ–™åº«æ˜¯å¦å·²æœ‰ç´€éŒ„
            existing = db.query(Video).filter(Video.file_hash == file_hash).first()
            if existing:
                if mode == "incremental":
                    print(f"â­ï¸  Already indexed (in DB): {video_path.name}")
                    already_in_db_count += 1
                    continue
                else:
                    # full æ¨¡å¼ï¼šé‡æ–°æ“·å–è³‡è¨Šä¸¦æ›´æ–°ç¾æœ‰ç´€éŒ„
                    print(f"ğŸ” Reprocessing (full mode): {video_path.name}")
                    video_info = extract_video_info(str(video_path))
                    file_metadata = parse_filename(video_path.name)

                    # åˆ¤æ–·ä½ç½®
                    location = "æœªçŸ¥"
                    if "LeYuan" in str(video_path) or "æ¨‚å«„" in str(video_path):
                        location = "æ¨‚å«„é‹å‹•ç©ºé–“"
                    elif "æ‹³æ“ŠåŸºåœ°" in str(video_path):
                        location = "æ‹³æ“ŠåŸºåœ°"

                    # æ›´æ–°æ¬„ä½ï¼ˆä¿ç•™åŸæœ‰ id / upload_dateï¼‰
                    existing.file_path = str(video_path)
                    existing.duration_seconds = video_info['duration_seconds']
                    existing.fps = video_info['fps']
                    existing.resolution = video_info['resolution']
                    existing.file_size_bytes = video_path.stat().st_size
                    existing.processing_status = "pending"
                    existing.training_date = file_metadata.get('training_date')
                    existing.training_type = file_metadata.get('training_type')
                    existing.location = location

                    db.add(existing)
                    db.commit()

                    seen_hashes.add(file_hash)
                    print(f"âœ… Updated: {video_path.name}")
                    updated_count += 1
                    continue
            
            # æå–å½±ç‰‡è³‡è¨Š
            print(f"ğŸ“Š Processing: {video_path.name}")
            video_info = extract_video_info(str(video_path))
            file_metadata = parse_filename(video_path.name)
            
            # åˆ¤æ–·ä½ç½®
            location = "æœªçŸ¥"
            if "LeYuan" in str(video_path) or "æ¨‚å«„" in str(video_path):
                location = "æ¨‚å«„é‹å‹•ç©ºé–“"
            elif "æ‹³æ“ŠåŸºåœ°" in str(video_path):
                location = "æ‹³æ“ŠåŸºåœ°"
            
            # å»ºç«‹è¨˜éŒ„
            video = Video(
                file_path=str(video_path),
                file_hash=file_hash,
                duration_seconds=video_info['duration_seconds'],
                fps=video_info['fps'],
                resolution=video_info['resolution'],
                file_size_bytes=video_path.stat().st_size,
                processing_status="pending",
                training_date=file_metadata.get('training_date'),
                training_type=file_metadata.get('training_type'),
                location=location
            )
            
            db.add(video)
            db.commit()
            
            seen_hashes.add(file_hash)
            print(f"âœ… Added: {video_path.name}")
            new_count += 1
            
        except Exception as e:
            print(f"âŒ Error processing {video_path.name}: {e}")
            error_count += 1
            continue
    
    db.close()
    
    print("\n" + "=" * 50)
    print("ğŸ“Š Scan Summary:")
    print(f"   New videos: {new_count}")
    print(f"   Updated (full mode): {updated_count}")
    print(f"   Already in DB: {already_in_db_count}")
    print(f"   Duplicates in this run: {duplicate_in_run_count}")
    print(f"   Errors: {error_count}")
    print(f"   Total processed: {len(video_files)}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="BoxTech Video Scanner")
    parser.add_argument("--directory", "-d", type=str, default="./Midea", help="Root directory to scan")
    parser.add_argument("--mode", "-m", type=str, default="incremental", choices=["incremental", "full"], help="Scan mode")
    args = parser.parse_args()

    print("ğŸ” BoxTech Video Scanner")
    print("=" * 50)
    print(f"Directory: {args.directory}")
    print(f"Mode: {args.mode}")
    scan_videos(directory=args.directory, mode=args.mode)
